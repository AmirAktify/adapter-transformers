{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from Suraj Patil's notebook on fine-tuning T5, see here: https://github.com/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_T_co' from 'typing' (C:\\Users\\hster\\AppData\\Local\\Programs\\Python\\Python37\\lib\\typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-cb5b6fa22491>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtransformers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mt5\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodeling_t5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mT5Model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mc:\\users\\hster\\pycharmprojects\\hiwi\\adapter-transformers\\src\\transformers\\models\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;31m# limitations under the License.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m from . import (\n\u001B[0m\u001B[0;32m     20\u001B[0m     \u001B[0malbert\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[0mauto\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hster\\pycharmprojects\\hiwi\\adapter-transformers\\src\\transformers\\models\\layoutlm\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m...\u001B[0m\u001B[0mfile_utils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m_BaseLazyModule\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mis_tf_available\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mis_tokenizers_available\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mis_torch_available\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mconfiguration_layoutlm\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mLAYOUTLM_PRETRAINED_CONFIG_ARCHIVE_MAP\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mLayoutLMConfig\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mtokenization_layoutlm\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mLayoutLMTokenizer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hster\\pycharmprojects\\hiwi\\adapter-transformers\\src\\transformers\\models\\layoutlm\\configuration_layoutlm.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m...\u001B[0m\u001B[0mutils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mlogging\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbert\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfiguration_bert\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mBertConfig\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hster\\pycharmprojects\\hiwi\\adapter-transformers\\src\\transformers\\models\\bert\\configuration_bert.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;34m\"\"\" BERT model configuration \"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m...\u001B[0m\u001B[0madapters\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel_mixin\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mModelConfigAdaptersMixin\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m...\u001B[0m\u001B[0mconfiguration_utils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPretrainedConfig\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m...\u001B[0m\u001B[0mutils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mlogging\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hster\\pycharmprojects\\hiwi\\adapter-transformers\\src\\transformers\\adapters\\model_mixin.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mcomposition\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mAdapterCompositionBlock\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mFuse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mStack\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparse_composition\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m from .configuration import (\n\u001B[0m\u001B[0;32m     11\u001B[0m     \u001B[0mADAPTERFUSION_CONFIG_MAP\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[0mDEFAULT_ADAPTERFUSION_CONFIG\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hster\\pycharmprojects\\hiwi\\adapter-transformers\\src\\transformers\\adapters\\configuration.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mcollections\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mabc\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mCollection\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mMapping\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mdataclasses\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mFrozenInstanceError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0masdict\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataclass\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfield\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mis_dataclass\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreplace\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtyping\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mList\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mOptional\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mUnion\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mIterator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_T_co\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_KT\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_VT_co\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mcomposition\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mAdapterCompositionBlock\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name '_T_co' from 'typing' (C:\\Users\\hster\\AppData\\Local\\Programs\\Python\\Python37\\lib\\typing.py)"
     ]
    }
   ],
   "source": [
    "from transformers.models.t5.modeling_t5 import T5Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    BartForConditionalGeneration,\n",
    "    BartTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule):\n",
    "  def __init__(self, hparams):\n",
    "    super(T5FineTuner, self).__init__()\n",
    "    self.hparams.update(hparams)\n",
    "    \n",
    "    self.model = T5ForConditionalGeneration.from_pretrained(hparams[\"model_name_or_path\"])\n",
    "    self.adapter_name = \"imdb\"\n",
    "    self.model.train()\n",
    "    self.model.add_adapter(self.adapter_name)\n",
    "    self.model.train_adapter(self.adapter_name)\n",
    "    \n",
    "    self.tokenizer = T5Tokenizer.from_pretrained(hparams[\"tokenizer_name_or_path\"])\n",
    "\n",
    "  \n",
    "  def forward(self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, labels=None):\n",
    "\n",
    "    return self.model(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        decoder_input_ids=decoder_input_ids,\n",
    "        decoder_attention_mask=decoder_attention_mask,\n",
    "        labels=labels,\n",
    "    )\n",
    "\n",
    "  def _step(self, batch):\n",
    "    labels = batch[\"target_ids\"]\n",
    "    labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "    outputs = self(\n",
    "        input_ids=batch[\"source_ids\"],\n",
    "        attention_mask=batch[\"source_mask\"],\n",
    "        labels=labels,\n",
    "        decoder_attention_mask=batch['target_mask']\n",
    "    )\n",
    "\n",
    "    loss = outputs[0]\n",
    "    return loss\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    loss = self._step(batch)\n",
    "    tensorboard_logs = {\"train_loss\": loss}\n",
    "    return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    loss = self._step(batch)\n",
    "    return {\"val_loss\": loss}\n",
    "  \n",
    "  def validation_epoch_end(self, outputs):\n",
    "    avg_loss = torch.stack([x[\"val_loss\"].mean() for x in outputs]).mean()\n",
    "    tensorboard_logs = {\"val_loss\": avg_loss}\n",
    "    return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "    model = self.model\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": self.hparams.weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
    "    self.opt = optimizer\n",
    "    return [optimizer]\n",
    "  \n",
    "  def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure=None, lambda_closure=None, second_order_closure=None, using_native_amp=None, using_lbfgs=None, on_tpu=False):\n",
    "    optimizer.step(closure=optimizer_closure)\n",
    "    optimizer.zero_grad()\n",
    "    self.lr_scheduler.step()\n",
    "  \n",
    "  def get_tqdm_dict(self):\n",
    "    tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
    "\n",
    "    return tqdm_dict\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\", args=self.hparams)\n",
    "    print(f\"retrieved {len(train_dataset)} examples for train\")\n",
    "    dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True, num_workers=1)\n",
    "    t_total = (\n",
    "        (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
    "        // self.hparams.gradient_accumulation_steps\n",
    "        * float(self.hparams.num_train_epochs)\n",
    "    )\n",
    "    print(f\"Retrieved {t_total} examples for dataloader\")\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
    "    )\n",
    "    self.lr_scheduler = scheduler\n",
    "    return dataloader\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"val\", args=self.hparams)\n",
    "    return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class LoggingCallback(pl.Callback):\n",
    "  def on_validation_end(self, trainer, pl_module):\n",
    "    logger.info(\"***** Validation results *****\")\n",
    "    metrics = trainer.callback_metrics\n",
    "    # Log results\n",
    "    for key in sorted(metrics):\n",
    "      if key not in [\"log\", \"progress_bar\"]:\n",
    "          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "\n",
    "  def on_test_end(self, trainer, pl_module):\n",
    "    logger.info(\"***** Test results *****\")\n",
    "    metrics = trainer.callback_metrics\n",
    "\n",
    "    # Log and save results to file\n",
    "    output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
    "    with open(output_test_results_file, \"w\") as writer:\n",
    "        for key in sorted(metrics):\n",
    "          if key not in [\"log\", \"progress_bar\"]:\n",
    "            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = dict(\n",
    "    data_dir='aclImdb', # path for data files\n",
    "    output_dir=\"\", # path to save the checkpoints\n",
    "    model_name_or_path='t5-base',\n",
    "    tokenizer_name_or_path='t5-base',\n",
    "    max_seq_length=256,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-8,\n",
    "    warmup_steps=100,\n",
    "    train_batch_size=16,\n",
    "    eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    gradient_accumulation_steps=1,\n",
    "    n_gpu=1,\n",
    "    fp_16=False, # if you want to enable 16-bit training then install apex and set this to true\n",
    "    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n",
    "    max_grad_norm=1.0, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!rm -rf aclImdb\n",
    "!tar -xvf aclImdb_v1.tar.gz\n",
    "!clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_files = glob.glob('aclImdb/train/pos/*.txt')\n",
    "train_neg_files = glob.glob('aclImdb/train/neg/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_pos_files), len(train_neg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir aclImdb/val aclImdb/val/pos aclImdb/val/neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_pos_files)\n",
    "random.shuffle(train_neg_files)\n",
    "\n",
    "val_pos_files = train_pos_files[:1000]\n",
    "val_neg_files = train_neg_files[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for f in val_pos_files:\n",
    "  shutil.move(f,  'aclImdb/val/pos')\n",
    "for f in val_neg_files:\n",
    "  shutil.move(f,  'aclImdb/val/neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbDataset(Dataset):\n",
    "  def __init__(self, tokenizer, data_dir, type_path,  max_len=512):\n",
    "    self.pos_file_path = os.path.join(data_dir, type_path, 'pos')\n",
    "    self.neg_file_path = os.path.join(data_dir, type_path, 'neg')\n",
    "    \n",
    "    self.pos_files = glob.glob(\"%s/*.txt\" % self.pos_file_path)\n",
    "    self.neg_files = glob.glob(\"%s/*.txt\" % self.neg_file_path)\n",
    "    \n",
    "    self.max_len = max_len\n",
    "    self.tokenizer = tokenizer\n",
    "    self.inputs = []\n",
    "    self.targets = []\n",
    "\n",
    "    self._build()\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.inputs)\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
    "    target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
    "\n",
    "    src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
    "    target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
    "\n",
    "    return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
    "  \n",
    "  def _build(self):\n",
    "    self._buil_examples_from_files(self.pos_files, 'positive')\n",
    "    self._buil_examples_from_files(self.neg_files, 'negative')\n",
    "  \n",
    "  def _buil_examples_from_files(self, files, sentiment):\n",
    "    REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "    for path in files:\n",
    "      with open(path, 'r') as f:\n",
    "        text = f.read()\n",
    "      \n",
    "        line = text.strip()\n",
    "        line = REPLACE_NO_SPACE.sub(\"\", line) \n",
    "        line = REPLACE_WITH_SPACE.sub(\"\", line)\n",
    "        line = line\n",
    "\n",
    "        target = sentiment\n",
    "\n",
    "        # tokenize inputs\n",
    "        tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
    "          [line], max_length=self.max_len, padding=\"max_length\", return_tensors=\"pt\",\n",
    "          truncation=True\n",
    "        )\n",
    "      \n",
    "        # tokenize targets\n",
    "        tokenized_targets = self.tokenizer.batch_encode_plus(\n",
    "          [target], max_length=2, padding=\"max_length\", return_tensors=\"pt\",\n",
    "          truncation=True\n",
    "        )\n",
    "\n",
    "        self.inputs.append(tokenized_inputs)\n",
    "        self.targets.append(tokenized_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"This is the most energetic and entertaining ten minutes of film >Ive seen in a long time As a film student at NYU where this >short has been screened several times I salute Jim Cox for his >astute sense of style and pace for our generation Im sure >Ill see his name later on the big screen Hopefully this short >will find a market on TV or somewhere so this inspiring work >can get the wide distribution it des\"\n",
    "b = tokenizer.encode(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p t5_imdb_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict.update({'data_dir': 'aclImdb', 'output_dir': 't5_imdb_sentiment', 'num_train_epochs': 2})\n",
    "args = argparse.Namespace(**args_dict)\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\", mode=\"min\", save_top_k=1\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "    gpus=args.n_gpu,\n",
    "    max_epochs=args.num_train_epochs,\n",
    "    precision= 16 if args.fp_16 else 32,\n",
    "    amp_level=args.opt_level,\n",
    "    gradient_clip_val=args.max_grad_norm,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(tokenizer, type_path, args):\n",
    "  return ImdbDataset(tokenizer=tokenizer, data_dir=args.data_dir, type_path=type_path,  max_len=args.max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5FineTuner(args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainable_params(model):\n",
    "    for name, parameters in model.named_parameters():\n",
    "        if parameters.requires_grad:\n",
    "            print(name)\n",
    "            \n",
    "get_trainable_params(model.model.encoder.block[0].layer[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(**train_params)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(tokenizer=tokenizer, type_path=\"train\", args=model.hparams)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImdbDataset(tokenizer, 'aclImdb', 'test',  max_len=512)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "it = iter(loader)\n",
    "batch = next(it)\n",
    "batch[\"source_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = model.model.cpu()\n",
    "\n",
    "outs = current_model.generate(\n",
    "    input_ids=batch['source_ids'].cpu(),\n",
    "    attention_mask=batch['source_mask'].cpu(), \n",
    "    max_length=2\n",
    ")\n",
    "\n",
    "dec = [tokenizer.decode(ids) for ids in outs]\n",
    "\n",
    "texts = [tokenizer.decode(ids) for ids in batch['source_ids']]\n",
    "targets = [tokenizer.decode(ids) for ids in batch['target_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_padding_tokens(input_string):\n",
    "    final_string = input_string.replace(\"<pad>\", \"\")\n",
    "    final_string = final_string.replace(\"</s>\", \"\")\n",
    "    return final_string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "for i in range(32):\n",
    "    lines = textwrap.wrap(\"Review:\\n%s\\n\" % texts[i], width=100)\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(\"\\nActual sentiment: %s\" % targets[i])\n",
    "    print(\"Predicted sentiment: %s\" % dec[i])\n",
    "    print(\"=====================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_texts = len(dataset)\n",
    "correct = 0\n",
    "incorrect = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs = []\n",
    "all_targets = []\n",
    "current_model = model.model.cuda()\n",
    "\n",
    "print(current_model.device)\n",
    "\n",
    "dataset = ImdbDataset(tokenizer, 'aclImdb', 'test',  max_len=256)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "it = iter(loader)\n",
    "\n",
    "for batch in tqdm(it, total=int(len(dataset)/32)):\n",
    "    outs = current_model.generate(\n",
    "        input_ids=batch['source_ids'].cuda(),\n",
    "        attention_mask=batch['source_mask'].cuda(), \n",
    "        max_length=2,\n",
    "        num_beams=1\n",
    "    )\n",
    "\n",
    "    decs = [tokenizer.decode(ids) for ids in outs]\n",
    "    targets = [tokenizer.decode(ids) for ids in batch['target_ids']]\n",
    "    \n",
    "    stripped_decs = [strip_padding_tokens(input_string) for input_string in decs]\n",
    "    stripped_targets = [strip_padding_tokens(target_string) for target_string in targets]\n",
    "    \n",
    "    all_outputs.extend(stripped_decs)\n",
    "    all_targets.extend(stripped_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(all_outputs, all_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}